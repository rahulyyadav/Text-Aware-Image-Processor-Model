![MIT License](https://img.shields.io/badge/license-MIT-green)
![Build](https://img.shields.io/badge/build-passing-brightgreen)
![Status](https://img.shields.io/badge/status-active-blue)

# Text-Aware Image Processor

**Text-Aware Image Processor** is a cost-efficient OCR pipeline that intelligently **pre-processes uploaded images to detect text presence before full image analysis**. By acting as a _pre-filter_ for LLM systems like ChatGPT and Gemini, this tool reduces compute loads by 70% on average — passing textual data directly to the LLM when possible, bypassing pixel-level vision inference.

Built with efficiency and scale in mind, this tool enables more users to upload _text-heavy images_ to LLMs without hitting capacity or latency limits.

---

## Key Features

- **Text-First Pipeline:** Detects text regions before triggering full OCR or vision models
- **LLM Optimization:** Filters and routes only relevant textual data to the language model
- **70% Reduction in Compute:** Lightweight, image-aware prefilter drastically reduces processing cost
- **Smart Table Renderer:** Reconstructs simple text tables with `|---|---|` style formatting for markdown compatibility
- **Built for ChatGPT & Gemini:** Enables higher throughput of document-based queries
- **Modular Integration:** Drop-in module for image-processing pipelines or browser plugins

---

## Use Case: How It Helps ChatGPT/Gemini

> "When a user uploads an image to GPTs, even if it contains just a few lines of text, the model still processes it pixel-by-pixel — costing bandwidth, inference time, and compute credits.  
> This tool intercepts the image, checks for dense textual content, and routes it directly as plain text.  
> End result? Faster response, lower cost, and more uploads per user session."

---

## How It Works

```txt
              ┌──────────────┐
     Image ──►│ Text Detector│─────┐
              └──────────────┘     │   No text?
                                   ├────► Send to Vision Model (OCR + VLM)
  Yes Text                         │
   Found?                          ▼
       ┌───────────────────────────────┐
       │ Use Optical Text Extraction   │
       │ Reconstruct markdown table    │
       │ Send plain text to LLM        │
       └───────────────────────────────┘
```

---

## Getting Started

**clone repo**

```md
git clone https://github.com/rahulyyadav/Text-Aware-Image-Processor-Model.git
```

```md
cd Text-Aware-Image-Processor-Model
```

**install requirements**

```md
pip install -r requirements.txt
```

**activate venv310**

```md
source venv310/bin/activate
```

**run main.py**

```md
python3.10 main.py
```

**note**

```md
There are two test images in /data you can check your own images.
```
